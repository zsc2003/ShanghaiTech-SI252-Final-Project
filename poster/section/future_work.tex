Stochastic Bandit:
\begin{itemize}
  \item Replace the linear preference function $H_{\theta}(a)$ with kernel methods or neural networks to enhance model expressiveness and policy flexibility.
  \item Combine the discrete diffusion process with Transformer-style autoregressive generation to further improve trajectory quality.
  \item Extend the discrete diffusion model to dynamic settings such as Restless Bandits, evaluating its effectiveness in more complex decision scenarios.
\end{itemize}


Contextual Bandit:
\begin{itemize}
    \item Integrating Bayesian principles (such as Bayesian diffusion models or model ensembling) into Diffusion to more effectively quantify and leverage epistemic uncertainty (exploration).
    
    \item Additionally, exploring more sophisticated risk-sensitive decision-making rules based on the full return distribution learned by Diffusion will also be a promising direction.
\end{itemize}